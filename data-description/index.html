<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Data description | pypi dependencies network</title>
<script src=https://cdn.tailwindcss.com></script><script src=https://unpkg.com/feather-icons></script><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style type=text/tailwindcss>
    @layer base {
        body {
          @apply bg-gray-100;
          @apply font-sans;
          @apply leading-normal;
          @apply tracking-normal;
        }
        p {
          @apply py-6;
        }
        a {
          @apply text-green-500;
          @apply no-underline;
          @apply hover:underline;
        }
        h1 {
          @apply py-2;
          @apply font-sans;
          @apply text-2xl;
        }
        h2 {
          @apply py-2;
          @apply font-sans;
          @apply text-xl;
        }
        h3 {
          @apply py-2;
          @apply font-sans;
          @apply text-lg;
        }
        ol {
          @apply px-8;
          @apply list-decimal;
        }
        ul {
          @apply px-8;
          @apply list-disc;
        }
        blockquote {
          @apply border-l-4; 
          @apply border-green-500;
          @apply italic;
          @apply my-8;
          @apply pl-8;
          @apply md:pl-12;
        }
        pre {
          @apply bg-gray-900;
          @apply rounded;
          @apply text-white; 
          @apply font-mono;
          @apply text-base;
          @apply my-4;
          @apply p-2;
          @apply md:p-4;
        }
        table {
          @apply shadow-md;
          @apply rounded-lg;
          @apply m-auto;
          @apply my-8;
        }
        thead {
          @apply bg-gray-50;
        }
        th {
          @apply py-3;
          @apply px-6;
          @apply text-xs;
          @apply font-medium;
          @apply tracking-wider;
          @apply text-left;
          @apply text-gray-700;
          @apply uppercase;
        }
        tr {
          @apply bg-white;
          @apply border-b;
        }
        td {
          @apply py-4;
          @apply px-6;
          @apply text-sm;
          @apply font-medium;
          @apply text-gray-900;
          @apply whitespace-nowrap;
        }
        img {
          @apply m-auto;
          @apply object-cover;
        }
        .footer-icon {
          width: 64px; 
          height: 64px;
          @apply mx-4;
        }
      }
    </style></head><body><nav id=header class="fixed w-full z-10 top-0"><div id=progress class="h-1 z-20 top-0" style="background:linear-gradient(to right,#4dc0b5 var(--scroll),transparent 0)"></div><div class="w-full md:max-w-4xl mx-auto flex flex-wrap items-center justify-between mt-0 py-3"><div class=pl-4><a class="text-gray-900 text-base no-underline hover:no-underline font-extrabold text-xl" href=https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/>pypi dependencies network</a></div><div class="block lg:hidden pr-4"><button id=nav-toggle class="flex items-center px-3 py-2 border rounded text-gray-500 border-gray-600 hover:text-gray-900 hover:border-green-500 appearance-none focus:outline-none"><svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"/></svg></button></div><div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden lg:block mt-2 lg:mt-0 bg-gray-100 md:bg-transparent z-20" id=nav-content><ul class="list-reset lg:flex justify-end flex-1 items-center list-none px-0"><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../data-description>Data</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../network-analysis>Network</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../text-analysis>Text</a></li></ul></div></div></nav><div class="container w-full md:max-w-3xl mx-auto pt-20"><div class="w-full px-4 md:px-6 text-xl text-gray-800 leading-normal" style=font-family:Georgia,serif><div class=font-sans><h1 class="font-bold font-sans break-normal text-gray-900 pt-6 pb-2 text-3xl md:text-4xl">Data description</h1></div><p>The first step was to collect the data. This process was a longer one, but the gain over doing it from scratch was the choice of what data to collect, and what to discard. The data acquisition was completed in the following steps:</p><ol><li>Get the packages of Pypi</li><li>Check for and retrieve the package&rsquo;s Github</li><li>Check for and retrieve information contained in a requirements file for dependencies</li><li>Check for and retireve the textual information in a README file.</li><li>Clean the collected information and make the edge list pairs.</li></ol><p>The data acquisition was done while running asyncronic, and was done using the library <strong>asyncio</strong>. Here the <em>seraphore</em> parameter was set to 500, which limits the number of concurrent tasks. Furthermore, <em>aiohttp</em> was used to keep a session running, when requesting to the same website multiple times.</p><p>First of a list of packages on Pypi was collected through a client server thorugh the library <em>xmlrpc.client</em>. It was a simple process of calling the packages available at the client:</p><pre tabindex=0><code>import xmlrpc.client as xc
client = xc.ServerProxy(&#39;http://pypi.python.org/pypi&#39;)
pypi_packages = client.list_packages()
</code></pre><p>In total over 500 thousand package names were retrived. Using <em>Beautiful Soup</em> requests for the package&rsquo;s links were sent in the form of <code>https://pypi.org/project/{package}/</code>, as this was the structure pypi was found to follow on their website. If this didn&rsquo;t exist, the package was discarded. By going through the website&rsquo;s structure, the relevant class name needed to check if a Github link existed, was located. If it did, it was saved, and if the package didn&rsquo;t have a Github, the package was still kept as it still could be pointed to as a dependency. This left around 350 thousand packages to then check for requirements and text.</p><p>When retrieving the README files and requirements a realization was made that a Github is structured, so that the user&rsquo;s content has a seperate URL starting with <strong>https//raw.githubusercontent.com</strong> follwed by the repository name, branch name, and then the file name. By checking Githubs of random small and big packages manually, it was found out that all of these had branches either named <strong>main</strong> or <strong>master</strong>, and README files ending with <em>.md, .rst or .txt</em>. Therefore, it was only necessary to check if any of these URLs exists for the given package. If a file is found it is cleaned through different Regular Expressions (RegEx) to streamline all the text for later analysis.</p><p>For the requirements file the same logic was applied. This time there was just more combinations to try, as the naming of the files varied more across the different Github repositories. From the ones we looked through a total of five different naming conventions were discovered:</p><ul><li>requirements-dev.txt</li><li>dev-requiremtns.txt</li><li>environment.yml</li><li>pyproject.toml</li><li>requirements.txt</li></ul><p>Depending on the found file format, different RegEx combinations were used to properly filter and clean the retrieved text into a list of the dependent package names. Additionally, if no requirements or README file was found that variable was just set as <em>None</em>, and thereby still keeping the node in the network to get as detailed a network as possible even though, it couldn&rsquo;t be used later for textual analysis. The final data size for the later text analysis were None values were dropped, was a total of 48,077 rows of different packages with at the start three columns of attributes. These were:</p><ul><li>The name of the library</li><li>A list of the requirements or empty</li><li>The text as one string or empty</li></ul><p>The URLs for pypi and Github were excluded from this dataframe, as that information was irrelevant for the analysis, but was still stored in other previous files made during data acquisition. Lastly the edge list was made to contian pairs of a requirement and the package it is used by. However, it was made sure to only allow dependency between packages that are originally on pypi, as this is the source investigated. So if a package is dependent on a package that can&rsquo;t be found on there, the pair is excluded. This list was afterwards used to create the directed graph.</p><hr class="border-b-2 border-gray-400 mt-8 mx-4"><div class="font-sans flex justify-between content-center px-4 pb-12"><div class=text-left><p><a href=https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/ class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">&lt;
Previous Page</a></p></div><div class=text-right><p><a href=../network-analysis class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">Next
Page ></a></p></div></div></div></div><footer class="bg-white border-t border-gray-400 shadow"><div class="container max-w-4xl mx-auto flex py-8"><div class="w-full mx-auto flex flex-col"><div class="flex w-full"><div class="px-8 mx-auto"><ul class="pt-3 list-none px-0 flex"><li><a class="text-gray-600 no-underline py-2" href=../explainer-notebook.html><i data-feather=file-text class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://github.com/MathiasDamsgaard/Comp_Social_Sci_Webpage><i data-feather=github class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href="https://drive.google.com/drive/folders/1ds2DuMk6-3qzciHKSTfHVpAQfmKQm407?usp=sharing"><i data-feather=hard-drive class=footer-icon></i></a></li></ul></div></div><div class="w-full mx-auto text-center"><ul class="list-reset items-center text-md py-6 list-none flex"><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Andreas Søndergaard (s214635)</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Anton Mosquera Storgaard (s214611)</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Mathias Correll Damsgaard (s214647)</p></li></ul></div></div></div></footer><script>var h=document.documentElement,b=document.body,st="scrollTop",sh="scrollHeight",progress=document.querySelector("#progress"),scroll,scrollpos=window.scrollY,header=document.getElementById("header"),navcontent=document.getElementById("nav-content");document.addEventListener("scroll",function(){scroll=(h[st]||b[st])/((h[sh]||b[sh])-h.clientHeight)*100,progress.style.setProperty("--scroll",scroll+"%"),scrollpos=window.scrollY,scrollpos>10?(header.classList.add("bg-white"),header.classList.add("shadow"),navcontent.classList.remove("bg-gray-100"),navcontent.classList.add("bg-white")):(header.classList.remove("bg-white"),header.classList.remove("shadow"),navcontent.classList.remove("bg-white"),navcontent.classList.add("bg-gray-100"))}),document.getElementById("nav-toggle").onclick=function(){document.getElementById("nav-content").classList.toggle("hidden")},feather.replace()</script></body></html>