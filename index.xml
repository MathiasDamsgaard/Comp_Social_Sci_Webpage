<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home Page on PyPi dependencies network</title><link>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/</link><description>Recent content in Home Page on PyPi dependencies network</description><generator>Hugo 0.125.0</generator><language>en</language><atom:link href="https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/helper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/helper/</guid><description>Link to something. italic, bold.
Math formula $$ x^n + y^n = z^n $$
Code chunk import pandas as pd df = pd.DataFrame() Highlight a section
Column 1 Column 2 Column 3 1 4 7 2 5 8 3 6 9 Two ways to insert an image List something Or with numbers</description></item><item><title>Data description</title><link>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/data-description/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/data-description/</guid><description>The first step was to collect the data. This process was a longer one, but the gain over doing it from scratch was the choice of what data to collect, and what to discard. The data acquisition was completed in the following steps:
Get the packages of PyPi Check for and retrieve the package&amp;rsquo;s Github Check for and retrieve information contained in a requirements file for dependencies Check for and retireve the textual information in a README file.</description></item><item><title>Network analysis</title><link>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/network-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/network-analysis/</guid><description>The aim of our Network analysis was to find out if the PyPi network had any meaningfullnes in its structure, what the nature of the network is and if there&amp;rsquo;s any significant nodes.
As mentioned in the description of the data the network is directed where a package points to its dependency.
Some basic statistics on the network&amp;rsquo;s largest weakly connect component are shown below:
Number of nodes: 31,304 Log ( Number of nodes ): 10.</description></item><item><title>Text analysis</title><link>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/text-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://MathiasDamsgaard.github.io/Comp_Social_Sci_Webpage/text-analysis/</guid><description>The last step of the analysis was about identifying communities within the large network of all the python packages and their requirements and investigate if packages that are related to similar tasks or fields within programming, form meaningful substructures in the network. To start this analysis the first task was to identify communities within the network. Since the network is relatively large with 31,304 nodes, we use the Louvain method for community detection as it performs well on large datasets and is shown that it has a very good accuracy in terms of decomposing the network in communities that have a modularity close to the optimal one.</description></item></channel></rss>